![img](https://github.com/jason-28/Learning-Note/blob/main/img/%E6%A9%9F%E7%B5%B11.jpg)

![img](https://github.com/jason-28/Learning-Note/blob/main/img/%E6%A9%9F%E7%B5%B12.jpg)

![img](https://github.com/jason-28/Learning-Note/blob/main/img/%E6%A9%9F%E7%B5%B13.jpg)

![img](https://github.com/jason-28/Learning-Note/blob/main/img/%E6%A9%9F%E7%B5%B14.jpg)

![img](https://github.com/jason-28/Learning-Note/blob/main/img/%E6%A9%9F%E7%B5%B15.jpg)

![img](https://github.com/jason-28/Learning-Note/blob/main/img/%E6%A9%9F%E7%B5%B16.jpg)

![img](https://github.com/jason-28/Learning-Note/blob/main/img/%E6%A9%9F%E7%B5%B17.jpg)

# Probability

## Terminology

* event(事件):一組樣本點所反映的事件。

* Random experiment(隨機試驗):能夠產生完整試驗結果的過程。

* Experimental outcome(試驗結果):真正發生的事件，也可稱為sample point(樣本點)。

* Sample Space(樣本空間):所有可能性結果的集合。

* Complement(補集):E.X.A的補集為非A的事件。

* Union (聯集) 

* Intersection (交集)

* Mutually Exclusive (互斥)

* Exhaustive event(完全事件):包含所有事件，但任兩事件彼此互斥。

* Prior probability(事前機率)

* Posterior probabilities(事後機率)

## Counting Rule 

* **Multiple-Step Experiments(多重步驟實驗):** 每個步驟只容許一個outcome。

* **Combinations(技術法則-組合):** 一次抽n個沒有順序。

* **Permutations(技術法則-排列):** 一次抽n個但有順序。

## Assigning Probabilities(指派機率)

* 機率介於0、1之間且全部可能性的機率加總為1。

**Classical Method(古典法):** 在每一個實驗結果發生可能性都相同時使用。

**Relative Frequency Method(相對次數法):** 根據實驗結果的歷史資料來決定機率多少。

**Subjective Method(主觀法):** 用主觀判斷、經驗來判斷機率。

* 古典法+主觀法或相對次數法+主觀法會是比較推薦的作法。

## Frequentist頻率學派

* 重複N次的抽樣試驗，只有5%的抽樣次數會是錯誤的。

* 缺點:無法定義事件發生的不確定性。

### The Concepts of 95% Confident Interval (CI):95%的信心認為這個區間會包含母體平均值/取樣N次，則有95%*N的CIs會涵蓋真正的母體平均值

* 一但抽出樣本，其樣本內之數值確立，則所計算所得之CI不是確實有涵蓋就是沒有涵蓋，不管 𝜇 是否有在此範圍，都不再涉及機率問題(有或沒有)。

## Bayes’ Theorem (貝氏定理)

* 在已知的一些條件下，某事件的發生機率(假設一開始只知道A 的機率，若可以再給予足夠B 的訊息，便可利用B再來對A做推論)。

* 母體參數θ並非一個固定未知定值，應將參數θ視為一個隨機變數。

* 在進行試驗前，研究者應對參數θ有些瞭解，則可給θ定一個事前分配(prior distribution)，此事前分配必須在抽樣之前設定。

* 在抽樣資料X收集完之後，ｘ應該是已知的，因此可以寫下概似函數(likelihood function)Ｌ(θ｜x)。

* 將抽樣的樣本資料和事前分配做結合，形成事後分配後，再去做推論。

* 可以得出95%的信心認為這個區間會包含樣本平均值的結論。

## Conditional Probability (條件機率)

* 在B 條件發生下，A 的機率為何

* 機率為：A 和B 交集的機率除以B 發生的機率(B 機率必須不為0)

## Independent Events (獨立事件)

* 若是在B 事件發生的條件下，A 事件發生的機率恰好等於A 事件本身的機率，且在A 事件發生的條件下，B 事件發生的機率也恰好等於B 事件本身發生的機率

* 知不知道A 並不影響B 的機率

* 在獨立事件的前提，A、B交集的機率 = P(A)P(B)= P(B)P(A|B)= P(A)P(B|A)

## 獨立事件不等於互斥事件

* 只有當A跟B獨立且P(B)=0 時，P(B|A)=P(B)=0，即P(B∩A)=0，才可以推論出A跟B為互斥。

# relative risk and odds ratio

## Evaluation of predictive models

### Regression 

* 連續型資料用，以下為指標:

**Mean absolute error:** 又稱 L1 損失, 是將每次測量的絕對誤差取絕對值後求的平均值, 用來觀察預測值誤差的測量是否要調整，用於資料中有沒有 outliers。

**Mean squared error:** 適合梯度計算。又稱 L2 損失, MSE 可以評價資料的變化程度，MSE 的值越小，說明預測模型描述實驗資料具有更好的精確度。

**R2:** 又稱為判定係數，是一種衡量回歸模型表現的指標，R2的值越接近1，表示迴歸模型擬合度越好。

### Confusion matrix (error matrix)

**TP (True Positive) — 真陽：** 即實際為True，預測為Positive。預測的結果與實際情況相同。

**TN (True Negative) — 真陰：** 即實際為True，預測為Negative。預測的結果與實際情況相同(Type I Error)。

**FP (False Positive) — 偽陽：** 即實際為False，預測為Positive。預測的結果與實際情況不同(Type II Error)。

**FN (False Negative) — 偽陰：** 即實際為False，預測為Negative。預測的結果與實際情況不同。

### Classification

* 類別型資料用，以下為指標:

**Accuracy(準確率):** (TP+TN)/(TP + TN + FP + FN) 成功預測的機率。

**Sensitivity(recall rate)(敏感度):** TP/(TP + FN) 所有positive中模型預測正確的機率 

**Specificity(特異度):** TN/(FP + TN) 所有negative中模型預測正確的機率。

**Precision(精確率):** TP/(TP + FP) 模型預測positive的數量中有多少真正positive。

**F1 score:** 2 * (precision * sensitivity) / (precision + sensitivity) 敏感度和精確率的調和平均數。

##  Receiver operating characteristic (ROC curve)

* 在各種『決策門檻』（decision threshold）下，比較『真陽率』與『假陽率』間的變化。

* ROC曲線下方覆蓋的面積Area Under Curve(AUC)越大，表示效能越好。

**TPF(真陽率):** true positive rate (Y axis)

**FPR(假陽率):** false positive rate (X axis)

### 如何判別最佳切點

* 若想讓 True positive最大、且 False positive最小，則選斜率變化最大。

* 若想降低 False Positive, 則選 score 較大的。

* 若想增加 True Positive, 則選 score 較小的。

* Senseitivity和Specificity 都大時，圖形上的點要靠近左上角，因此要尋找的就是最靠近左上角的點

* 若數據資料都落在對角線，表示要檢測的與test 是獨立的，有沒有test 的結果都是一樣的，因此落在線上的點是沒有用的檢測

## Relative Risk (RR) 相對危險性

* 用於前瞻性研究

* 不適用於回溯性研究，因為研究是從事件中去挑選資料，事件的機率是由研究者決定，可能就會發生偏差。

* E.X.暴露於危險因子的人當中得病的機率/沒暴露於危險因子的人當中得病的機率

## Odds ratio勝算比

* 分析收集資料的方式與RR不同

* E.X.暴露於危險因子的人當中，生病的比上不生病的人的勝算/沒暴露於危險因子的人當中，生病比上不生病的人的勝算

# Probability	Distributions

## Discrete	Probability	Distributions	(離散機率分配)

### Random	Variables (隨機變數)

* 用數值來反映其背後的隨機現象。

* 以機率決定該數值的變數，通常以X、Y、T、U…大寫字母表示。

**Discrete	random	variable(離散隨機變數):** 取用隨機變數的值與自然數有一對一的對應，可為有限或無限。

**Continuous	random	variable(連續隨機變數):** 取用隨機變數的值在某一區間或區間集合的所有可能數值。

### Probability	Distributions (機率密度函數)

* 離散隨機變數的機率密度函數一般稱為probability mass function(pmf)機率質量函數。

* 連續隨機變數的機率密度函數一般稱為probability density	function(pdf)機率密度函數。

### Uniform distribution(離散型均勻分配)

* 有N個結果，各結果的機率均相同。

### Bernoulli	Distribution(白努利分配)

* 其隨機變數值只有兩種可能將之表示為 X	=	{0,	1}，習慣上令 X	=	1	的機率為 p而 X	=	0	的機率為 q(即1-p)，p即為白努利分配的參數。

### Binomial Probability	Distribution (二項機率分配)

* 為取出放回。

* 重複試驗操作 Bernoulli trial 共 n 次，其試驗總合之隨機變數的機率分佈即為二項式分佈。

* **二項式定理：** 根據二項式定理，( p + ( 1 – p ) )n = 1n得其機率總合為1。

### 中央極限定理

* p接近0.5時會呈現類似鐘型的曲線

* n越大，點越密集，看起來就像是連續的

* 資料雖不呈常態分配(e.g.,	懷孕時胎兒之染色體為XY的機率)，但若是從母群體中抽取一個夠大的樣本 (e.g.,	n	=	100)，並計算其平均值，則此些樣本平均值所組成的新群體必定接近常態分佈。

### Poisson	(卜瓦松) Probability	Distribution

* 隨機變數只能以整數表示。

* 在可接受的偏差範圍內可以有效估計隨機變數的機率分佈，而不需要複雜的計算。

* 任意兩段等長的時間區段、其事件的發生速率是相等的。

* 任意兩個時間區段、其事件發生與否是獨立的。

* E(x)=	Var(x)	為 Poisson	distribution的特色。當N很大，而考慮其中的稀有事件時，一般會假設Poisson	 distribution	描述其分佈，而可以用E(x)	=	Var(x) 這個特色檢驗這個假設是否正確。

* 若 p 極小，圖形應該往左偏。越偏向右，越不像Poisson distribution(用於稀有事件)，λ值越大，圖形就越呈鐘型對稱。

* 若λ為每天期望看到此事件的次數，則λ值越高，代表每天可以看到的次數越多，不符合卜瓦松的特性，建議改用常態分配。

### Hypergeometric(超幾何)	Probability	Distribution

* 為取出不放回。

* 在資料料夠大時可以視為進行N次嘗試的白努利分配

### Bivariate	distribution(二元分配)

* 用於檢視兩個變數的關係。

**Covariance(共變異數):** 用於衡量隨機變數間的相關程度。

**Correlation	coefficient(相關係數):** 也可以當作線性相依性。

* 相關性=1時稱為「完全線性相依」，=-1時稱為「完全線性負相關」。

* 相關性為0（因而共變異數也為0）的兩個隨機變數又被稱為是不相關的，或者更準確地說叫作「線性獨立」、「線性不相關」，並非表示它們之間一定沒有任何內在的（非線性）函數關係。

## Continuous	Probability	Distributions(連續型機率分配)

### Uniform	Probability	Distribution(連續型均勻分配)

* 簡單來說就是每個等長區間上取值的機率都一樣。

### Normal	Probability	Distribution (常態分配)

* 如同Poisson	distribution都是用來approximate	二項式分佈的方法，可處理連續型變數。

* 一旦mean與variance	確定即決定出圖形的樣子。

* 常態分布通常是集中且light	tail;相對來說在兩極端所佔的比例很少，但也有些分配是heavy	tail。

**標準常態分配:** 平均值為0，標準差為1的常態分配。

**標準化的優點：** 把任何一個常態分布經由上面公式的轉換後，則可查表得 N	( 0,	1	)的曲線下面積，不需要一直用積分的方式去運算。

### Exponential	Probability	Distribution(指數分配)

* 可以用來表示獨立隨機事件發生的時間間隔。

* Poisson	distribution找的是事件數，指數分配找的是時間。

# Hypothesis	Testing(假設檢定)

* 決定一個數值透過母體參數產生的是否可以信任。

* 信任就是對立假設，反之虛無假設；通常對立假設就是研究論點。

## Student T	test

* 用假設檢定評估一個或兩個母體平均數的工具。可用於評估一個群組是否偏離已知值 (單樣本檢定)、兩個群組是否彼此不同 (獨立雙樣本t檢定)；或配對測量值是否有顯著差異 (配對或相依樣本t檢定)。

* 用於母體平均數未知的情況。

**degrees	of	freedom(自由度):** 以樣本的統計量來估計母體的母數時，樣本中獨立或能自由變化的數據的個數；隨著自由度越高會越接近常態分配。

### p-Value Approach to One-Tailed Hypothesis Testing p 值法單尾假設檢定

* p的意思是 probability,如果 p-value 越小且小於顯著性測試 α，就可以拒絕虛無假設。

* 設定顯著性測試 z與結果的 z 來判斷是否支持虛無假設。

### Critical Value Approach to One-Tailed Hypothesis Testing 臨界值假設檢定

* 透過標準常態機率分配的z值來判斷，設定一個面積，只要檢測值落在z面積上就可以拒絕此假設。

## Interval	Estimation(區間估計)

* 對欲估計母體參數值提供可能發生的範圍（區間），並提供該區間會包含母體參數的機率值（信賴程度）

## Confidence	Interval(信賴區間)

* 點估計(point	estimate)：使用樣本資料計算出單一數字來估計所要的參數，其缺點為無法提供估計值變異性的資訊。

* 區間估計(interval	estimate):提供所欲包含參數(母群體平均數)之合理數值範圍，並給予頗有把握之可信度，該數值範圍稱為信賴區間。

**Lower-tail左尾:** H0=μ≥u0,H1=μ<u0
 
**Upper-tail右尾:** H0=μ≤u0,H1=μ<u0

**Two-tailed 雙尾:** H0=μ=u0,H1=μ!=u0

* 雙尾信賴區間(Two-Sided	Confidence Interval):有上、下限範圍之區間。

* 單尾信賴區間(One-Sided	Confidence Interval):在某些狀況下，我們僅關心母群體平均值μ的上限或μ的下限，而非μ所座落的區間。

* 受到以下因素影響:信賴程度、樣本大小、變異數。

* 如何維持樣本的信賴程度但縮短信賴區間的長度:增加樣本數。

# ANOVA

* 目的：找出很多個母群體是否有相異

* 方法：假設所有母體的變異數相同，利用從各組母體抽出的樣本的變異程度來估計母體的mean值是否相同，藉由組間和組內的差異來猜測各樣本是不是由相同的母體抽出的。

1. 用 Sample Means 的Variance來估計各母體之間的離散度(Between MSS )

2. 用 Sample Variance 來估計各個母體內部的差異程度(即組內變異Within MSS)

* 將總變異分成「組間的變異」和「組內的變異」。

## TSS(總離均差平方和)

* 所有抽樣的個體與全體平均值的差異，就是把各組的數值混在一起，每個值都去算離overall mean 有多遠，即為多組間的總變異量。

* d.f.(自由度)：總共有k 組，每一組都包含n 個人→有nk 個人，扣掉全體平均值之後自由度就為nk-1。

* Variance(變異數)不等同於variation，sum of squares是一種variation，「差異的絕對值與變異數」亦為variation，只能說Variance是一種variation。

## BSS

* 各組之間的差異，算法是把各組的平均值算出來，再比較各組平均值之間的差異，各組平均值的平均＝總體平均。

* d.f：有k 組所以得到k 個組平均值，求各組平均值的平均，所以在k個值當中有一個是平均，需要扣掉=>d.f=k-1。

## WSS

* 各組內部的差異，把每一組的成員與這組的平均值比較差異。

* d.f.=每一組有n 個人，與其平均值作比較，組員中有一個是平均值，所以把它扣掉，又我們有k 個sample populations，故乘k=>d.f.=(n-1)k。

## Chi-Square Distribution(齊一式檢定)

* 把標準常態分配平方以後變成新的分配。

* 當一個隨機變數是常態分配，那它做了一些數學上的轉換(例如轉換成平方)成了新的隨機變數，也會產生新的分配。

* n 個互相獨立的標準常態分配平方相加後、形成之新的分配，其自由度為n。

**Degree of freedom:** 一個標準常態分配只有一個變數，所以平方後所產生的卡方分配自由度是１;若兩個獨立的標準常態分配平方相加後，自由度會變成２。

### F Distribution

* F value should be positive, since F = MSR/MSE

* 分母和分子都為一些平方的相加，故F 統計量必為正的，F 的數值範圍為（0，∞）

* F 分配兩個自由度誰大誰小並不一定,但基於ANOVA test的運算 : 分子MSR之自由度為（k-1），分母MSE之自由度為（n-1）k，所以分母之自由度大於分子之自由度。

* 當每組的平均值等同於母體平均值，反應各組之間的平均值沒有顯著差異，就呈現組與組之間的差異、猶如個體的變異，上下相除 F ≒ 1。

* 雖然只看單尾，但是其實是雙尾檢定：檢定μ相不相等，而非誰比較大(由於MSR與MSE 的運算裡有經過平方，所以無法判斷出是誰大誰小，只能檢定是否相等)。

### Rejection region

* 指各組的母體期望值差很多，當MSR（between group）很大，MSE 很小，導致F 統計量很大（＞１）時，則會落入rejection region。

* 大於1 的區域應該都屬於拒絕區，因為大於1 代表各組母體期望值不全等。

* 拒絕區之大小由顯著水準決定。
